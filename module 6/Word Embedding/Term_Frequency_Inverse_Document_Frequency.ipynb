{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeEMGRXdRmMd",
        "outputId": "64c89ea9-5092-4f20-d75f-d2fbfe85a572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text corpus includes 202651 words.\n",
            "Word count: 11446 e.g.: ['abandon' 'abase' 'abate' 'abated' 'abbey' 'abbot' 'abed' 'abel' 'abet'\n",
            " 'abhor']\n",
            "Embedding shape: (10, 11446)\n"
          ]
        }
      ],
      "source": [
        "# load the dataset\n",
        "with open(\"input.txt\", \"r\") as file:\n",
        "    corpus = file.read()\n",
        "\n",
        "print(f\"Text corpus includes {len(corpus.split())} words.\")\n",
        "\n",
        "# to simulate multiple documents, we chunk up the corpus into 10 pieces\n",
        "N = len(corpus) // 10\n",
        "documents = [corpus[i:i+N] for i in range(0, len(corpus), N)]\n",
        "\n",
        "documents = documents[:-1] #last document is residue\n",
        "# now we have N documents from the corpus\n",
        "# Text corpus includes 202651 words.\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "embeddings = vectorizer.fit_transform(documents)\n",
        "words = vectorizer.get_feature_names_out()\n",
        "\n",
        "print(f\"Word count: {len(words)} e.g.: {words[:10]}\")\n",
        "print(f\"Embedding shape: {embeddings.shape}\")\n",
        "### OUTPUT ###\n",
        "# Word count: 11446 e.g.: ['abandon' 'abase' 'abate' 'abated' 'abbey' 'abbot' 'abed' 'abel' 'abet' 'abhor']\n",
        "# Embedding shape: (10, 11446)"
      ]
    }
  ]
}