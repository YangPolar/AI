{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqJYYj3EXZCb",
        "outputId": "e11bf69f-0c6a-4ecb-ef2e-8b2c550a48c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.20.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2026.1.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting first 10 models available in Hugging Face\n",
        "from huggingface_hub import HfApi\n",
        "from getpass import getpass\n",
        "\n",
        "api = HfApi(token=getpass(\"Enter HuggingFace Token: \"))\n",
        "\n",
        "# models = api.list_models()\n",
        "# print(\"HuggingFace Models:\", models[:10])  # printing only first 10\n",
        "\n",
        "from itertools import islice\n",
        "\n",
        "models = api.list_models()\n",
        "first10 = list(islice(models,10))\n",
        "for i in first10:\n",
        "  print(\"HuggingFace Models:\", i.id)\n",
        "\n",
        "# list of models on website-https://huggingface.co/models\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEBJNceKXnll",
        "outputId": "72587b49-0170-40e2-a53f-eb7852752410"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter HuggingFace Token: ··········\n",
            "HuggingFace Models: zai-org/GLM-Image\n",
            "HuggingFace Models: fal/Qwen-Image-Edit-2511-Multiple-Angles-LoRA\n",
            "HuggingFace Models: Lightricks/LTX-2\n",
            "HuggingFace Models: openbmb/AgentCPM-Explore\n",
            "HuggingFace Models: kyutai/pocket-tts\n",
            "HuggingFace Models: Kijai/LTXV2_comfy\n",
            "HuggingFace Models: google/medgemma-1.5-4b-it\n",
            "HuggingFace Models: google/translategemma-4b-it\n",
            "HuggingFace Models: Supertone/supertonic-2\n",
            "HuggingFace Models: Qwen/Qwen3-VL-Embedding-8B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting the Number of models available in Huggung Face\n",
        "from huggingface_hub import HfApi\n",
        "from getpass import getpass\n",
        "api = HfApi(token=getpass(\"Enter HuggingFace Token: \"))\n",
        "count = 0\n",
        "for _ in api.list_models():\n",
        "    count += 1\n",
        "\n",
        "print(\"Total Models:\", count)\n"
      ],
      "metadata": {
        "id": "Q-JWImWjYyyw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count number of BERT models\n",
        "from huggingface_hub import HfApi\n",
        "from getpass import getpass\n",
        "api = HfApi(token=getpass(\"Enter HuggingFace Token: \"))\n",
        "count = 0\n",
        "# count number of bert models\n",
        "for _ in api.list_models(filter=\"bert\"):\n",
        "    count += 1\n",
        "\n",
        "print(\"BERT Models:\", count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwRSdbfYZovB",
        "outputId": "10ddd109-5941-4cd2-fdd4-ff92c46930ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter HuggingFace Token: ··········\n",
            "BERT Models: 84172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counting of number of text-classification models\n",
        "from huggingface_hub import HfApi\n",
        "from getpass import getpass\n",
        "api = HfApi(token=getpass(\"Enter HuggingFace Token: \"))\n",
        "count = 0\n",
        "\n",
        "for _ in api.list_models(filter=\"text-classification\"):\n",
        "    count += 1\n",
        "\n",
        "print(\"Text Classification Models:\", count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc05IMbGanTB",
        "outputId": "e7ee04e0-427b-4ec8-d8a7-64a84ef52eb3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter HuggingFace Token: ··········\n",
            "Text Classification Models: 110068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counting of llama Models\n",
        "\n",
        "from huggingface_hub import HfApi\n",
        "from getpass import getpass\n",
        "\n",
        "token = getpass(\"Enter HuggingFace Token: \")\n",
        "api = HfApi(token=token)\n",
        "\n",
        "models = list(api.list_models(author=\"meta\", search=\"llama\"))\n",
        "\n",
        "for m in models[:20]:\n",
        "    print(m.modelId)\n",
        "\n",
        "\n",
        "# models = api.list_models(author=\"meta\", search=\"llama\")\n",
        "# for m in models[:20]:\n",
        "#     print(m.modelId)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9gvKze8cfdg",
        "outputId": "ff157eb2-fe41-4555-f5f8-9b5390a20e55"
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter HuggingFace Token: ··········\n"
          ]
        }
      ]
    }
  ]
}